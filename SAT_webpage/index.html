<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SAT">
  <meta name="keywords" content="SAT, spatial aptitude training, spatial intelligence, LLM, MLM, langauge models, multimodal, multimodal language models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SAT: Dynamic Spatial Aptitude Training for Multimodal Language Models </title>


  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./SAT_webpage/static/css/bulma.min.css">
  <link rel="stylesheet" href="./SAT_webpage/static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./SAT_webpage/static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./SAT_webpage/static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./SAT_webpage/static/css/index.css">
  <link rel="icon" href="./SAT_webpage/static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./SAT_webpage/static/js/fontawesome.all.min.js"></script>
  <script src="./SAT_webpage/static/js/bulma-carousel.min.js"></script>
  <script src="./SAT_webpage/static/js/bulma-slider.min.js"></script>
  <script src="./SAT_webpage/static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://arijitray1993.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SAT: Dynamic Spatial Aptitude Training for Multimodal Language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
                <a href="https://arijitray1993.github.io/">Arijit Ray</a><sup>1</sup>,
            </span>
            <span class="author-block">
                <a href="https://duanjiafei.com/">Jiafei Duan</a><sup>2 &dagger;</sup>,
            </span>
            <span class="author-block">
              <a href="https://duanjiafei.com/">Ellis Brown</a><sup>2 &dagger;</sup>,
          </span>
            <span class="author-block">
                <a href="https://cs-people.bu.edu/rxtan/">Reuben Tan</a><sup>1,4</sup>,
            </span>
            <span class="author-block">
                <a href="https://scholar.google.com/citations?user=qvUTYsUAAAAJ&hl=en">Dina Bashkirova</a><sup>1</sup>,
            </span>
            <span class="author-block">
                <a href="https://rosehendrix.com/">Rose Hendrix</a><sup>3</sup>,
            </span>
            <span class="author-block">
                <a href="https://ehsanik.github.io/">Kiana Ehsani</a><sup>3</sup>,
            </span>
            <span class="author-block">
                <a href="https://anikem.github.io/">Aniruddha Kembhavi</a><sup>3</sup>,
            </span>
            <span class="author-block">
                <a href="https://bryanplummer.com/">Bryan A. Plummer</a><sup>1</sup>,
            </span>
            <span class="author-block">
                <a href="https://ranjaykrishna.com/index.html">Ranjay Krishna</a><sup>2,3*</sup>,
            </span>
            <span class="author-block">
                <a href="https://kuohaozeng.github.io/">Kuo-Hao Zeng</a><sup>3*</sup>,
            </span>
            <span class="author-block">
                <a href="http://ai.bu.edu/ksaenko.html">Kate Saenko</a><sup>1*</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Boston University,</span>
            <span class="author-block"><sup>2</sup>University of Washington,</span>
            <span class="author-block"><sup>3</sup>Allen AI,</span>
            <span class="author-block"><sup>4</sup>Microsoft Research (MSR)</span>
            <span class="author-block"><sup>5</sup>New York University</span>
          </div>
          <div class="is-size-6 publication-authors">
            *equal advising, &dagger; joint second author
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://cs-people.bu.edu/array/research/SAT/SAT_arxiv.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2412.07755"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code coming soon!</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/array/SAT" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">SAT</span> is a dynamic spatial aptitude training dataset requiring reasoning about ego and object motions that go beyond simple static relationships in existing datasets.
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
          <img src="./SAT_webpage/static/images/SAT_COLM_teaser_2.jpg" alt="SAT Teaser" width="150%"> 
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Reasoning about motion and space is a fundamental cognitive capability that is required by multiple real-world applications. 
          While many studies highlight that large multimodal language models (MLMs) struggle to reason about space, 
          they only focus on static spatial relationships, and not dynamic awareness of motion and space, i.e.,
           reasoning about the effect of egocentric and object motions on spatial relationships. Manually annotating such 
           object and camera movements is expensive. Hence, we introduce SAT, a simulated spatial aptitude training dataset 
           comprising both static and dynamic spatial reasoning across 175K question-answer (QA) pairs and 20K scenes. 
           Complementing this, we also construct a small (150 image-QAs) yet challenging dynamic spatial test set using real-world images.
            Leveraging our SAT datasets and 6 existing static spatial benchmarks, we systematically investigate what improves both
             static and dynamic spatial awareness. Our results reveal that simulations are surprisingly effective at imparting
              spatial aptitude to MLMs that translate to real images. We show that perfect annotations in simulation are more
               effective than existing approaches of pseudo-annotating real images. For instance, SAT training improves a 
               LLaVA-13B model by an average 11% and a LLaVA-Video-7B model by an average 8% on multiple spatial benchmarks, 
               including our real-image dynamic test set and spatial reasoning on long videos -- even outperforming some 
               large proprietary models. While reasoning over static relationships improves with synthetic training data, 
               there is still considerable room for improvement for dynamic reasoning questions.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Approach. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Approach</h2>
        <div class="content has-text-centered">
          <img src="./SAT_webpage/static/images/SATApproach.png" alt="SAT Approach" class="interpolation-image" width="100%">
          We take actions in a 3D simulator and check the 3D locations of assets. We use
natural language descriptions of the assets and make QA pairs based on how the 3D nature of the scene changes with the actions taken.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <hr>
        <div class="content has-text-centered">
          <h4 class="title is-5">Open-source MLMs struggle on our dynamic spatial reasoning as well as large proprietary models despite stronger static spatial performance</h4>
          <img src="./SAT_webpage/static/images/sat_eval.png" alt="SAT Tasks" class="interpolation-image" width="75%">
        </div>
      </div>
    </div>
    
    <hr>
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h5 class="title is-5">Fine-tuning on SAT improves spatial performance on existing static benchmarks</h5>
      </div>
    </div>
    
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <div class="column content"> 
          <img src="./SAT_webpage/static/images/staticeval.png" alt="SAT Tasks" class="interpolation-image" width="80%">
        </div>
      </div>
          
    </div>
  
    <hr>
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h5 class="title is-5">Fine-tuning on SAT improves performance on a video spatial benchmark, VSI-Bench (Yang et al, 2024)</h5>
      </div>
    </div>
    
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <div class="column content"> 
          <img src="./SAT_webpage/static/images/vsieval.png" alt="SAT Tasks" class="interpolation-image" width="60%">
        </div>
      </div>
          
    </div>

  </div>
  
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{ray2025satdynamicspatialaptitude,
      title={SAT: Dynamic Spatial Aptitude Training for Multimodal Language Models}, 
      author={Arijit Ray and Jiafei Duan and Ellis Brown and Reuben Tan and Dina Bashkirova and Rose Hendrix and Kiana Ehsani and Aniruddha Kembhavi and Bryan A. Plummer and Ranjay Krishna and Kuo-Hao Zeng and Kate Saenko},
      year={2025},
      eprint={2412.07755},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.07755}, 
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>